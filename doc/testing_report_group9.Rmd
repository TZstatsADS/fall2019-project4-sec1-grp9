---
title: "Project4"
output: html_notebook
---

In this project, we are going to explore matrix factorization methods for recommender system. The goal is to match consumers with most appropriate products. Matrix factorization methods characterize both items and users by vectors of factors inferred from item rating patterns. High correspondence between item and user factors leads to a recommendation. Matrix factorization generally has 3 parts:

- factorization algorithm

- regularization

- postpocessing

We are going to compare P2 vs P3 given A3 + R3.

### Step 1 Load Data and Train-test Split
```{r,message=FALSE}

library(dplyr)
library(tidyr)
library(ggplot2)
library(foreach)
library(doParallel)
library(zoo)
library(Matrix)
library(lubridate)

source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation.R")

set.seed(123)

data <- read.csv("../data/ml-latest-small/ratings.csv")
dataSplit <- train_test_split(data,0.8) #this function ensures that all users and movies are in the training set.
data_train <- dataSplit$train
data_test <- dataSplit$test

```


###Step 2 Matrix Factorization
#### Step 2.1 Algorithm and Regularization
Here we perform alternating least squares to do matrix factorization and use temporal dynamics as our regularization term.

- For algorithms, the referenced paper are:

A3. [Alternating Least Squares](./paper/P4 Large-scale Parallel Collaborative Filtering for the Netflix Prize.pdf) Section 3.1

R3. [Temporal Dynamics](./paper/P5 Collaborative Filtering with Temporal Dynamics.pdf) Section 4 linear model

First, we initialize matrix q by assigning the average rating for that movie as the first row, and small random numbers for the remaining entries. Next we fixe p, solve q by minimizeing the objective function. Then we fixe p, solve q by minimizing the objective funciton similarly. After that, we use temporal dynamics as regularization terms. We use alternative least squares to update one parameter and fix the other parameter. 

We write a function als.t to do matrix factorization. The function is in Matrix_Factorization.R file in the lib folder.
```{r}
source("../lib/Matrix_Factorization.R")
```


#### Step 2.2 Parameter Tuning

Conducting a full Cross-Validation was very time consuming. Given our time constraints, we tested 6 set of parameters only once. Uncomment the commented section of the code if the user wishes to run the testing process.

```{r, message=FALSE}

f_list <- c(10,20)
l_list <- c(0.01,0.05,0.1)
f_l <- expand.grid(f_list, l_list)

# resultList <- list()
# run_time <- system.time(for(i in 1:nrow(f_l)){
#   par <- paste("f = ", f_l[i,1], ", lambda = ", f_l[i,2])
#   cat(par, "\n")
#   
#   current_result  <- als.t(f = f_l[i,1],  lambda = f_l[i,2],max.iter = 10,data = data, train = data_train, test = data_test)
#   resultList[[paste0('f = ',f_l[i,1],' , lambda = ',f_l[i,2])]] <- current_result
#   
#   
# })
# 
# save(resultList, file = "../output/CVResult.RData")

load('../output/CVResult.RData')
resultNms <- as.list(names(resultList))
rmse <- do.call(rbind,lapply(resultNms, FUN = function(nm){
  x <- resultList[[nm]]$RMSE
  rbind(data.frame(train_test = 'Train',par = nm,Iteration = x$Iteration,RMSE = x$Train.Q.Update,check.names = F),
        data.frame(train_test = 'Test',par = nm,Iteration = x$Iteration,RMSE = x$Test.Q.Update,check.names = F)
  )
}))

rmse %>% ggplot(aes(x = Iteration, y = RMSE, col = train_test)) + geom_point() + 
  facet_grid(~par,labeller = label_wrap_gen(width = 16,multi_line = TRUE)) + scale_x_continuous(breaks = c(0,5,10),labels = c('0','5','10'))


```
  
We can see that the parameter set f = 10, lambda = 0.1 gives use the best outcome. Furthermore, running 3-4 iterations is enough to get the best result.

### Fitting the model with the optimized parameters

```{r}
# registerDoParallel(cores = detectCores())# use parallelization for faster procesing
# result <- als.t(f = 10,  lambda = 0.1,max.iter = 3,data = data, train = data_train, test = data_test)
# 
# save(result,file = "../output/ALSResult.RData")
load('../output/ALSResult.RData')
result$RMSE
```


### Step 3 Postprocessing
After matrix factorization, postporcessing will be performed to improve accuracy. We use Postprocessing SVD with KNN (P2) and Postprocessing SVD with kernel (P3) to do postprocessing.

P2:[Postprocessing SVD with KNN](./paper/P2 Improving regularized singular value decomposition for collaborative filtering .pdf) Section 3.5

P3:[Postprocessing SVD with kernel ridge regression](./paper/P2 Improving regularized singular value decomposition for collaborative filtering .pdf) Section 3.6

We write a function pred_rating_svd_knn to perform Postprocessing SVD with KNN, which is in the p2_scd_knn.R file in the lib folder. 
#### P2 - Postprocessing SVD with KNN
```{r}
source(file = "../lib/p2_svd_knn.R")
## calculate similarity matrix 
q <- result$q
p2_result_test <- pred_rating_svd_knn(data_train = data_train, data_test = data_test, q)
pred_test_adj <- p2_result_test['pred_test']
test_rmse_p2 <- p2_result_test['rmse_test']
print(test_rmse_p2)
save(test_rmse_p2, file = "../output/test_rmse_p2.Rdata")
```

#### P3 - Postprocessing SVD with kernel ridge regression 
```{r}
library("pracma")
norm_vec <- function(x) {return(x/Norm(x))}
norm_q <- apply(result$q, 2, norm_vec)
library("listdtr")
movieID <- colnames(result$q)
MSE <- list()
for(i in 1:610){
  userID = as.character(i)
  print(userID)
  movie_train_index <- which(movieID %in% data_train$movieId[which(data_train$userId == userID)])
  movie_test_index <- which(movieID %in% data_test$movieId[which(data_test$userId == userID)])
  obj <- krr(t(norm_q[, movie_train_index]), data_train$rating[movie_train_index])
  xnew <- norm_q[, movie_test_index]
  ynew <- predict(obj, t(xnew))
  ytrue <- data_test$rating[which(data_test$userId == userID)]
  MSE_ <- mean((ynew - ytrue)^ 2)
  MSE <- append(MSE, MSE_)
}
MSE <- mean(unlist(MSE))
test_rmse_p3 <- mean(MSE)
print(test_rmse_p3)
save(test_rmse_p3, file = "../output/test_rmse_p3.Rdata")
```

### Step 4 Evaluation
Finally, we compare the rmse of P2 and P3 given A3 + R3. The result is shown in the table below.

```{r}
library(knitr)
test_rmse = c(as.numeric(test_rmse_p2), as.numeric(test_rmse_p3))

compare_df <- data.frame(method = c('P2','P3'), test_rmse = test_rmse)

kable(compare_df, caption = 'Comparision of RMSE for P2 vs P3 given A3 + R3')
```

The test_rmse of Postprocessing SVD with KNN (P2) is smaller, so we can conclude given A3 + R3, P2 is better than P3.